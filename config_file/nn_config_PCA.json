{
    "layers": [ 3],

    "activations": ["relu", "softmax"],

    "optimizer": "adam",
    "learning_rate": 0.0001,
    "momentum": 0.09,

    "dropout": 0,
    "batch_norm": true,

    "epochs": 210,
    "batch_size": 200,

    "loss": "categorical_crossentropy",
    "metrics": ["accuracy"]
}